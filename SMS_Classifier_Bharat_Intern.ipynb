{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EIjt6FqI15R7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/sample_data/spam.csv\",encoding=\"latin\")  # Replace with your file path\n",
        "\n",
        "X = data[\"v2\"]  # Extract text messages\n",
        "y = data[\"v1\"]  # Extract labels (spam, non-spam)"
      ],
      "metadata": {
        "id": "haFC1woq2QE-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7sPPBu_F508M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=2000)  # Adjust max_features as needed\n",
        "X_train_features = vectorizer.fit_transform(X_train)\n",
        "X_test_features = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "N1cRQtlX6DvI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
        "    \"Logistic Regression\": LogisticRegression(solver=\"lbfgs\"),\n",
        "    \"Support Vector Machine\": SVC(kernel=\"linear\"),\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_features, y_train)\n",
        "    y_pred = model.predict(X_test_features)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred,pos_label=\"ham\")\n",
        "    recall = recall_score(y_test, y_pred,pos_label=\"ham\")\n",
        "    f1 = f1_score(y_test, y_pred,pos_label=\"ham\")\n",
        "\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts2JKIHz6Gan",
        "outputId": "6ba2aa92-7620-4b69-9963-e601e85cf7da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: Multinomial Naive Bayes\n",
            "Accuracy: 0.9749\n",
            "Precision: 0.9718\n",
            "Recall: 1.0000\n",
            "F1-score: 0.9857\n",
            "\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.9704\n",
            "Precision: 0.9679\n",
            "Recall: 0.9990\n",
            "F1-score: 0.9832\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.9812\n",
            "Precision: 0.9807\n",
            "Recall: 0.9979\n",
            "F1-score: 0.9892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example parameter tuning for LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lr = LogisticRegression(solver=\"lbfgs\")\n",
        "param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10]}\n",
        "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring=\"accuracy\")\n",
        "grid_search.fit(X_train_features, y_train)\n",
        "best_model = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "lRyoX4Al6I_U"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Example saving the best LogisticRegression model as \"spam_classifier.pkl\"\n",
        "joblib.dump(best_model, \"spam_classifier.pkl\")\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex07aI3A7Zuz",
        "outputId": "17509ae7-e303-44b8-8b2a-2b8aa8c2cf45"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = joblib.load(\"spam_classifier.pkl\")\n",
        "vectorizer = joblib.load(\"vectorizer.pkl\")  # Load the trained vectorizer\n",
        "\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocesses text for better model performance.\"\"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "def predict_spam_percentage(text):\n",
        "    \"\"\"Predicts the spam percentage for a given text input.\"\"\"\n",
        "    processed_text = preprocess_text(text)  # Apply any necessary preprocessing\n",
        "    text_features = vectorizer.transform([processed_text])\n",
        "    prediction = model.predict_proba(text_features)[0][1]  # Get probability of spam\n",
        "    spam_percentage = prediction * 100\n",
        "    return spam_percentage\n",
        "\n",
        "# Example usage\n",
        "input_text = \"Congratulations! You've won a free prize! Click here to claim: bit.ly/freeprize\"\n",
        "spam_percentage = predict_spam_percentage(input_text)\n",
        "print(\"Spam Percentage:\", spam_percentage)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsMGMaz37v0J",
        "outputId": "e5680382-22b9-40b0-cc25-2e0138d9b59a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Percentage: 94.92959719107768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2-4_xbj71I0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}